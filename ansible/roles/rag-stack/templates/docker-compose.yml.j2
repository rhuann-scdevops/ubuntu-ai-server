# =============================================================================
# RAG Stack Docker Compose Reference
# =============================================================================
# This file is for reference. Containers are managed by Ansible.
# Generated by: ansible-playbook site.yml --tags rag-stack
# =============================================================================

version: "3.8"

services:
  # ===========================================================================
  # Qdrant - Vector Database
  # ===========================================================================
  qdrant:
    image: qdrant/qdrant:{{ rag_stack.qdrant.version }}
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "{{ rag_stack.qdrant.port }}:6333"
      - "{{ rag_stack.qdrant.grpc_port }}:6334"
    volumes:
      - {{ rag_stack.data_path }}/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__LOG_LEVEL=INFO
    networks:
      - ai-network

{% if rag_stack.docling.enabled %}
  # ===========================================================================
  # Docling API - Document Parser
  # ===========================================================================
  docling-api:
    image: {{ rag_stack.docling.image }}
    container_name: docling-api
    restart: unless-stopped
    ports:
      - "{{ rag_stack.docling.port }}:8080"
    volumes:
      - {{ rag_stack.data_path }}/docling/input:/app/input
      - {{ rag_stack.data_path }}/docling/output:/app/output
      - {{ rag_stack.documents_path }}:/app/documents:ro
    environment:
      - LOG_LEVEL=INFO
    networks:
      - ai-network
{% endif %}

{% if rag_stack.interpreter.enabled %}
  # ===========================================================================
  # Open Interpreter - Code Execution Sandbox
  # ===========================================================================
  open-interpreter:
    image: {{ rag_stack.interpreter.image }}
    container_name: open-interpreter
    restart: unless-stopped
    ports:
      - "{{ rag_stack.interpreter.port }}:8000"
    volumes:
      - {{ rag_stack.data_path }}/interpreter:/home/user
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - INTERPRETER_MODE=server
      - SANDBOX_ENABLED=true
      - OLLAMA_HOST=http://ollama:11434
      - DEFAULT_MODEL={{ rag_stack.interpreter.default_model }}
{% if rag_stack.interpreter.gpu_enabled %}
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
{% endif %}
    networks:
      - ai-network
{% endif %}

{% if rag_stack.anythingllm.enabled %}
  # ===========================================================================
  # AnythingLLM - RAG Frontend
  # ===========================================================================
  anythingllm:
    image: mintplexlabs/anythingllm:{{ rag_stack.anythingllm.version }}
    container_name: anythingllm
    restart: unless-stopped
    ports:
      - "{{ rag_stack.anythingllm.port }}:3001"
    volumes:
      - {{ rag_stack.data_path }}/anythingllm:/app/server/storage
      - {{ rag_stack.documents_path }}:/app/documents:ro
    environment:
      - STORAGE_DIR=/app/server/storage
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_PATH=http://ollama:11434
      - OLLAMA_MODEL_PREF={{ rag_stack.anythingllm.default_model }}
      - EMBEDDING_ENGINE=ollama
      - EMBEDDING_MODEL_PREF=nomic-embed-text
      - EMBEDDING_BASE_PATH=http://ollama:11434
      - VECTOR_DB=qdrant
      - QDRANT_ENDPOINT=http://qdrant:6333
    networks:
      - ai-network
{% endif %}

  # ===========================================================================
  # RAG Ingestion Service
  # ===========================================================================
  rag-ingestion:
    build:
      context: {{ rag_stack.data_path }}/ingestion
      dockerfile: Dockerfile
    image: rag-ingestion:latest
    container_name: rag-ingestion
    restart: unless-stopped
    ports:
      - "{{ rag_stack.ingestion.port }}:8000"
    volumes:
      - {{ rag_stack.data_path }}/ingestion/config.yml:/app/config.yml:ro
      - {{ rag_stack.documents_path }}:/app/documents:ro
      - {{ rag_stack.data_path }}/docling/output:/app/parsed
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OLLAMA_HOST=http://ollama:11434
      - EMBEDDING_MODEL=nomic-embed-text
      - NEO4J_URI=bolt://neo4j-mcp:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD={{ mcp.neo4j.password }}
    depends_on:
      - qdrant
    networks:
      - ai-network

networks:
  ai-network:
    external: true
