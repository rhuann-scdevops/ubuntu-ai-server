"""
DevOps Agent
Autonomous agent for infrastructure management and automation tasks.
Adapted for LangChain 1.x using LCEL and tool calling.
"""
from typing import Optional, List, Dict, Any
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.messages import HumanMessage, AIMessage

from config import get_settings, MODEL_CONFIGS
from tools import (
    DockerStatusTool,
    ServiceStatusTool,
    FileReadTool,
    ShellCommandTool,
    KnowledgeSearchTool,
)


DEVOPS_SYSTEM_PROMPT = """You are an expert DevOps engineer assistant with access to various tools for infrastructure management.

Your capabilities include:
- Checking Docker container status and health
- Monitoring systemd services
- Reading configuration files and logs
- Executing safe shell commands for system info
- Searching the knowledge base for documentation

Guidelines:
1. Always verify before taking action - check current state first
2. Use the appropriate tool for each task
3. Provide clear explanations of what you find
4. Suggest next steps when troubleshooting
5. Be cautious with any commands that could affect system state
6. Reference documentation from the knowledge base when relevant

When the user asks you to perform a task:
1. Analyze what information you need
2. Describe what tools you would use and why
3. Provide actionable recommendations

Remember: Safety first. Only use read-only operations unless explicitly asked to make changes."""


class DevOpsAgent:
    """DevOps Agent for infrastructure management using LCEL."""

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: float = 0.2,
        verbose: bool = False
    ):
        self.settings = get_settings()
        self.model_name = model_name or self.settings.default_chat_model
        self.temperature = temperature
        self.verbose = verbose

        self.llm = ChatOllama(
            base_url=self.settings.ollama_url,
            model=self.model_name,
            temperature=self.temperature
        )

        self.tools = [
            DockerStatusTool(),
            ServiceStatusTool(),
            FileReadTool(),
            ShellCommandTool(),
            KnowledgeSearchTool(),
        ]

        self.chain = self._build_chain()

    def _build_chain(self):
        """Build the DevOps agent chain using LCEL."""
        prompt = ChatPromptTemplate.from_messages([
            ("system", DEVOPS_SYSTEM_PROMPT),
            MessagesPlaceholder("chat_history", optional=True),
            ("human", "{input}")
        ])

        return prompt | self.llm | StrOutputParser()

    def _format_tools_description(self) -> str:
        """Format available tools as a string for context."""
        tool_descriptions = []
        for tool in self.tools:
            tool_descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(tool_descriptions)

    async def ainvoke(
        self,
        task: str,
        chat_history: List[tuple] = None
    ) -> Dict[str, Any]:
        """Async execute a DevOps task."""
        history = []
        if chat_history:
            for human, ai in chat_history:
                history.append(HumanMessage(content=human))
                history.append(AIMessage(content=ai))

        # Add tool context to the task
        enhanced_task = f"""{task}

Available tools for reference:
{self._format_tools_description()}

Provide your analysis and recommendations based on DevOps best practices."""

        result = await self.chain.ainvoke({
            "input": enhanced_task,
            "chat_history": history
        })

        return {
            "output": result,
            "intermediate_steps": []  # LCEL doesn't track intermediate steps the same way
        }

    def invoke(
        self,
        task: str,
        chat_history: List[tuple] = None
    ) -> Dict[str, Any]:
        """Sync execute a DevOps task."""
        history = []
        if chat_history:
            for human, ai in chat_history:
                history.append(HumanMessage(content=human))
                history.append(AIMessage(content=ai))

        # Add tool context to the task
        enhanced_task = f"""{task}

Available tools for reference:
{self._format_tools_description()}

Provide your analysis and recommendations based on DevOps best practices."""

        result = self.chain.invoke({
            "input": enhanced_task,
            "chat_history": history
        })

        return {
            "output": result,
            "intermediate_steps": []
        }

    async def analyze_docker(self, container_name: Optional[str] = None) -> Dict[str, Any]:
        """Analyze Docker containers status."""
        task = "Analyze the Docker environment"
        if container_name:
            task = f"Analyze the Docker container: {container_name}"
        return await self.ainvoke(task)

    async def analyze_service(self, service_name: str) -> Dict[str, Any]:
        """Analyze a systemd service."""
        return await self.ainvoke(f"Analyze the systemd service: {service_name}")


def create_devops_agent(
    model_config: str = "general",
    verbose: bool = False
) -> DevOpsAgent:
    """Factory function to create a DevOps agent."""
    config = MODEL_CONFIGS.get(model_config, MODEL_CONFIGS["general"])
    return DevOpsAgent(
        model_name=config["model"],
        temperature=config["temperature"],
        verbose=verbose
    )
