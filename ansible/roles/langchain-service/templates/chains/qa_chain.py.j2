"""
Question-Answering Chains
Direct Q&A chains without retrieval for general knowledge queries.
"""
from typing import Optional, Dict, Any, List
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_ollama import ChatOllama

from config import get_settings, MODEL_CONFIGS


class QAChain:
    """
    Simple Q&A chain for direct questions without document retrieval.
    """

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: float = 0.7,
        system_prompt: Optional[str] = None
    ):
        self.settings = get_settings()
        self.model_name = model_name or self.settings.default_chat_model
        self.temperature = temperature

        self.system_prompt = system_prompt or """You are a helpful AI assistant.
Provide accurate, concise, and helpful responses to user questions.
If you're unsure about something, say so clearly."""

        self.llm = ChatOllama(
            base_url=self.settings.ollama_url,
            model=self.model_name,
            temperature=self.temperature
        )

        self.chain = self._build_chain()

    def _build_chain(self):
        """Build the Q&A chain."""
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("human", "{question}")
        ])

        return prompt | self.llm | StrOutputParser()

    async def ainvoke(self, question: str) -> str:
        """Async invoke the Q&A chain."""
        return await self.chain.ainvoke({"question": question})

    def invoke(self, question: str) -> str:
        """Sync invoke the Q&A chain."""
        return self.chain.invoke({"question": question})

    async def astream(self, question: str):
        """Async stream responses."""
        async for chunk in self.chain.astream({"question": question}):
            yield chunk


class NOCExpertChain(QAChain):
    """Specialized Q&A chain for NOC expertise."""

    NOC_SYSTEM_PROMPT = """You are an expert NOC (Network Operations Center) technician with deep expertise in:

**Satellite Systems:**
- VSAT terminals (Intellian, Cobham, KVH)
- Antenna systems (Seatel, Sailor, TracPhone)
- Satellite orbits (GEO, MEO, LEO including Starlink)

**Network Equipment:**
- Cisco IOS/IOS-XE routers and switches
- Juniper Junos devices
- Palo Alto firewalls
- Fortinet FortiGate

**SD-WAN:**
- Versa Networks (Director, Analytics, FlexVNF)
- Cisco SD-WAN (vManage, vSmart, vBond)

When answering:
1. Be specific and actionable
2. Provide command examples when relevant
3. Consider impact and risks
4. Suggest verification steps"""

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: float = 0.3
    ):
        settings = get_settings()
        super().__init__(
            model_name=model_name or settings.noc_expert_model,
            temperature=temperature,
            system_prompt=self.NOC_SYSTEM_PROMPT
        )


class CodeAnalysisChain(QAChain):
    """Specialized Q&A chain for code analysis and generation."""

    CODE_SYSTEM_PROMPT = """You are an expert software engineer and code analyst.

Your capabilities include:
- Code review and analysis
- Bug identification and fixes
- Code optimization suggestions
- Infrastructure as Code (Ansible, Terraform, Kubernetes)
- Shell scripting (Bash, PowerShell)
- Python development
- Docker and container configurations

When providing code:
1. Use proper formatting with language-specific syntax highlighting
2. Include comments for complex logic
3. Consider edge cases and error handling
4. Follow best practices and conventions"""

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: float = 0.2
    ):
        settings = get_settings()
        super().__init__(
            model_name=model_name or settings.default_code_model,
            temperature=temperature,
            system_prompt=self.CODE_SYSTEM_PROMPT
        )


def create_qa_chain(
    model_config: str = "general",
    system_prompt: Optional[str] = None
) -> QAChain:
    """Factory function to create a Q&A chain with predefined model config."""
    if model_config == "noc":
        return NOCExpertChain()
    elif model_config == "code":
        return CodeAnalysisChain()

    config = MODEL_CONFIGS.get(model_config, MODEL_CONFIGS["general"])
    return QAChain(
        model_name=config["model"],
        temperature=config["temperature"],
        system_prompt=system_prompt
    )
