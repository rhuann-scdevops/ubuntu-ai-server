"""
Summary Chains
Chains for summarizing documents, logs, and other content.
"""
from typing import Optional, List, Dict, Any
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_ollama import ChatOllama
from langchain.chains.summarize import load_summarize_chain
from langchain_text_splitters import RecursiveCharacterTextSplitter

from config import get_settings, MODEL_CONFIGS


class SummaryChain:
    """Chain for summarizing various types of content."""

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: float = 0.3,
        chain_type: str = "stuff"
    ):
        self.settings = get_settings()
        self.model_name = model_name or self.settings.default_chat_model
        self.temperature = temperature
        self.chain_type = chain_type

        self.llm = ChatOllama(
            base_url=self.settings.ollama_url,
            model=self.model_name,
            temperature=self.temperature
        )

        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.settings.chunk_size,
            chunk_overlap=self.settings.chunk_overlap
        )

    def _get_chain(self, prompt_type: str = "general"):
        """Get the appropriate summary chain with custom prompt."""
        prompts = {
            "general": """Write a concise summary of the following content:

{text}

CONCISE SUMMARY:""",

            "technical": """Provide a technical summary of the following documentation:

{text}

Include:
- Key concepts and features
- Important configurations
- Notable limitations or requirements

TECHNICAL SUMMARY:""",

            "log": """Analyze and summarize the following log entries:

{text}

Include:
- Overall status/health assessment
- Key events or errors found
- Patterns or anomalies detected
- Recommended actions if any

LOG ANALYSIS SUMMARY:""",

            "config": """Summarize the following configuration:

{text}

Include:
- Main purpose/function
- Key settings and their values
- Security considerations
- Dependencies or requirements

CONFIGURATION SUMMARY:""",

            "incident": """Summarize the following incident report or troubleshooting session:

{text}

Include:
- Problem description
- Root cause (if identified)
- Resolution steps taken
- Prevention recommendations

INCIDENT SUMMARY:"""
        }

        prompt_template = prompts.get(prompt_type, prompts["general"])
        prompt = ChatPromptTemplate.from_template(prompt_template)

        return load_summarize_chain(
            self.llm,
            chain_type=self.chain_type,
            prompt=prompt if self.chain_type == "stuff" else None
        )

    async def asummarize(
        self,
        text: str,
        prompt_type: str = "general"
    ) -> str:
        """Async summarize text content."""
        docs = [Document(page_content=text)]

        if len(text) > self.settings.chunk_size * 2:
            docs = self.text_splitter.create_documents([text])

        chain = self._get_chain(prompt_type)
        result = await chain.ainvoke(docs)
        return result["output_text"]

    def summarize(
        self,
        text: str,
        prompt_type: str = "general"
    ) -> str:
        """Sync summarize text content."""
        docs = [Document(page_content=text)]

        if len(text) > self.settings.chunk_size * 2:
            docs = self.text_splitter.create_documents([text])

        chain = self._get_chain(prompt_type)
        result = chain.invoke(docs)
        return result["output_text"]


class LogSummaryChain(SummaryChain):
    """Specialized chain for log analysis and summarization."""

    def __init__(self, model_name: Optional[str] = None):
        super().__init__(
            model_name=model_name,
            temperature=0.2,
            chain_type="stuff"
        )

    async def analyze_logs(self, log_content: str) -> Dict[str, Any]:
        """Analyze logs and provide structured output."""
        analysis_prompt = ChatPromptTemplate.from_template("""Analyze the following logs and provide a structured analysis:

{logs}

Provide your analysis in the following format:

## Status
[Overall health: HEALTHY/WARNING/CRITICAL]

## Key Events
- [List important events]

## Errors Found
- [List any errors with timestamps if available]

## Patterns
- [Any recurring patterns or anomalies]

## Recommendations
- [Suggested actions]

ANALYSIS:""")

        chain = analysis_prompt | self.llm | StrOutputParser()
        analysis = await chain.ainvoke({"logs": log_content})

        return {
            "analysis": analysis,
            "log_length": len(log_content),
            "line_count": log_content.count('\n') + 1
        }


class ConfigSummaryChain(SummaryChain):
    """Specialized chain for configuration analysis."""

    def __init__(self, model_name: Optional[str] = None):
        super().__init__(
            model_name=model_name,
            temperature=0.2,
            chain_type="stuff"
        )

    async def analyze_config(
        self,
        config_content: str,
        config_type: str = "generic"
    ) -> Dict[str, Any]:
        """Analyze configuration and provide insights."""
        analysis_prompt = ChatPromptTemplate.from_template("""Analyze the following {config_type} configuration:

{config}

Provide your analysis including:

## Purpose
[What this configuration does]

## Key Settings
| Setting | Value | Description |
|---------|-------|-------------|
[List important settings]

## Security Assessment
- [Any security concerns or best practices]

## Dependencies
- [Required services, ports, or configurations]

## Recommendations
- [Optimization or improvement suggestions]

ANALYSIS:""")

        chain = analysis_prompt | self.llm | StrOutputParser()
        analysis = await chain.ainvoke({
            "config": config_content,
            "config_type": config_type
        })

        return {
            "analysis": analysis,
            "config_type": config_type,
            "config_length": len(config_content)
        }


def create_summary_chain(
    summary_type: str = "general",
    model_config: str = "general"
) -> SummaryChain:
    """Factory function to create summary chains."""
    config = MODEL_CONFIGS.get(model_config, MODEL_CONFIGS["general"])

    if summary_type == "log":
        return LogSummaryChain(model_name=config["model"])
    elif summary_type == "config":
        return ConfigSummaryChain(model_name=config["model"])

    return SummaryChain(
        model_name=config["model"],
        temperature=config["temperature"]
    )
